{"workflowName":"munge_sumstats","workflowProcessingEvents":[{"cromwellId":"cromid-812b784","description":"PickedUp","timestamp":"2021-11-24T16:14:47.496Z","cromwellVersion":"71-c778c33"},{"cromwellId":"cromid-812b784","description":"Finished","timestamp":"2021-11-24T16:14:52.852Z","cromwellVersion":"71-c778c33"}],"actualWorkflowLanguageVersion":"draft-2","submittedFiles":{"workflow":"task clean_filter {\n\n    String docker\n    File sumstat_file\n    String af_col\n    Float min_af\n    String info_col\n    Float min_info\n    String outfile = sub(basename(sumstat_file, \".gz\"), \"\\\\.bgz$\", \"\") + \".munged.AF.\" + min_af + \".INFO.\" + min_info + \".gz\"\n    String dollar = \"$\"\n\n    command <<<\n\n        #TODO use pandas or something\n\n        echo \"COVID-19 HGI meta-analysis - clean and filter sumstats\"\n        echo \"${sumstat_file}\"\n        echo \"\"\n\n        catcmd=\"cat\"\n        if [[ ${sumstat_file} == *.gz ]] || [[ ${sumstat_file} == *.bgz ]]\n        then\n            catcmd=\"zcat\"\n        fi\n\n        echo \"`date` original number of variants\"\n        $catcmd ${sumstat_file} | tail -n+2 | wc -l\n\n        chr_col=$($catcmd ${sumstat_file} | head -1 | tr '\\t ' '\\n' | grep -nx \"CHR\" | head -1 | cut -d ':' -f1)\n        pos_col=$($catcmd ${sumstat_file} | head -1 | tr '\\t ' '\\n' | grep -nx \"POS\" | head -1 | cut -d ':' -f1)\n        printf \"`date` col CHR \"${dollar}{chr_col}\" col POS \"${dollar}{pos_col}\"\\n\"\n\n        $catcmd ${sumstat_file} | awk ' \\\n          BEGIN{FS=\"\\t| \"; OFS=\"\\t\"}\n          NR==1 {\n              for (i=1;i<=NF;i++) { sub(\"^INFO$\", \"${info_col}\", $i); sub(\"^Rsq$\", \"${info_col}\", $i); sub(\"^CHR\", \"#CHR\", $i); a[$i]=i; if ($i==\"POS\") pos=i }\n              gsub(\"Pvalue\", \"p.value\", $0);\n              print $0\n          } NR>1 {\n              sub(\"^0\", \"\", $a[\"#CHR\"]); sub(\"^chr\", \"\", $a[\"#CHR\"]); sub(\"^X\", \"23\", $a[\"#CHR\"]);\n              if ($a[\"#CHR\"] ~ /^[0-9]+$/ && $a[\"p.value\"] != 0 && $a[\"BETA\"] < 1e6 && $a[\"BETA\"] > -1e6 && $a[\"${af_col}\"]>${min_af} && (1-$a[\"${af_col}\"])>${min_af} && $a[\"${info_col}\"]>${min_info}) {\n                  printf $1\n                  for (i=2; i<=NF; i++) {\n                      if (i==pos) {\n                          printf \"\\t%d\", $i\n                      } else {\n                          printf \"\\t\"$i\n                      }\n                  }\n                  printf \"\\n\"\n              }\n          }' | \\\n        sort -k$chr_col,${dollar}{chr_col}g -k$pos_col,${dollar}{pos_col}g -u | \\\n        bgzip > ${outfile}\n        tabix -S 1 -s $chr_col -b $pos_col -e $pos_col ${outfile}\n\n        echo \"`date` new number of variants\"\n        gunzip -c ${outfile} | tail -n+2 | wc -l\n        echo \"`date` headers\"\n        gunzip -c ${outfile} | head -1 | tr '\\t' '\\n'\n\n        gunzip -c ${outfile} | tail -n+2 | cut -f $chr_col | uniq > chr.tmp\n        echo \"`date` $(wc -l chr.tmp | cut -d' ' -f1) chromosomes\"\n        cat chr.tmp\n\n        echo \"`date` unique number of fields\"\n        gunzip -c ${outfile} | awk 'BEGIN{FS=\"\\t\"} {print NF}' | sort -u > n.tmp\n        cat n.tmp\n        if [ $(wc -l n.tmp | cut -d' ' -f1) != 1 ]; then echo \"file not square\"; exit 1; fi\n        if [ $(wc -l chr.tmp | cut -d' ' -f1) -lt 22 ]; then echo \"less than 22 chromosomes\"; exit 1; fi\n\n        echo \"`date` done\"\n\n    >>>\n\n    output {\n        File out = outfile\n        File tbi = outfile + \".tbi\"\n    }\n\n    runtime {\n        docker: \"${docker}\"\n        cpu: \"1\"\n        memory: \"2 GB\"\n        disks: \"local-disk 200 HDD\"\n        zones: \"us-east1-d\"\n        preemptible: 2\n        noAddress: true\n    }\n}\n\ntask lift {\n\n    String docker\n    File sumstat_file\n    File tbi_file = sumstat_file + \".tbi\"\n    String base = basename(sumstat_file)\n    File b37_ref\n    File b38_ref\n    String dollar = \"$\"\n\n    command <<<\n\n        echo \"COVID-19 HGI meta-analysis - lift over sumstats if needed\"\n        echo \"${sumstat_file}\"\n        echo \"${b37_ref}\"\n        echo \"${b38_ref}\"\n        echo \"\"\n\n        mv ${sumstat_file} ${base}\n        mv ${tbi_file} ${base}.tbi\n\n        tabix -R ${b37_ref} ${base} | wc -l > b37.txt\n        tabix -R ${b38_ref} ${base} | wc -l > b38.txt\n\n        echo \"`date` `cat b37.txt` chr 21 variants build 37\"\n        echo \"`date` `cat b38.txt` chr 21 variants build 38\"\n\n        if ((`cat b37.txt` == 0 && `cat b38.txt` == 0)); then\n            echo \"`date` no chr 21 variants found in either build, quitting\"\n            exit 1\n        fi\n\n        if ((`cat b37.txt` > `cat b38.txt`)); then\n            echo \"`date` lifting to build 38\"\n            time /META_ANALYSIS/scripts/lift.py -chr \"#CHR\" -pos POS -ref Allele1 -alt Allele2 \\\n            -chain_file /liftover/hg19ToHg38.over.chain.gz -tmp_path /cromwell_root/ \\\n            ${base} > ${base}.lift.out 2> ${base}.lift.err\n            gunzip -c ${base}.lifted.gz | \\\n            cut -f2- | awk '\n            BEGIN { FS=OFS=\"\\t\" }\n            NR==1 { for (i=1;i<=NF;i++) a[$i]=i; print $0 }\n            NR>1 {\n                temp=$a[\"#CHR\"]; $a[\"#CHR\"]=$a[\"anew_chr\"]; $a[\"anew_chr\"]=temp; temp=$a[\"POS\"]; $a[\"POS\"]=$a[\"anew_pos\"]; $a[\"anew_pos\"]=temp;\n                sub(\"^0\", \"\", $a[\"#CHR\"]); sub(\"^chr\", \"\", $a[\"#CHR\"]); sub(\"^X\", \"23\", $a[\"#CHR\"]);\n                if ($a[\"#CHR\"] ~ /^[0-9]+$/) {\n                    print $0\n                }\n            }' | bgzip > ${base}\n        else\n            echo \"`date` presumably already in build 38\"\n        fi\n\n    >>>\n\n    output {\n        File out = base\n    }\n\n    runtime {\n        docker: \"${docker}\"\n        cpu: \"1\"\n        memory: \"2 GB\"\n        disks: \"local-disk 200 HDD\"\n        zones: \"us-east1-d\"\n        preemptible: 2\n        noAddress: true\n    }\n}\n\ntask harmonize {\n\n    String docker\n    File sumstat_file\n    String base = basename(sumstat_file)\n    File gnomad_ref\n    String gnomad_ref_base = basename(gnomad_ref)\n    Int n\n    String options\n\n    command <<<\n\n        echo \"COVID-19 HGI meta-analysis - harmonize sumstats to reference\"\n        echo \"${sumstat_file}\"\n        echo \"${gnomad_ref}\"\n        echo \"\"\n\n        mv ${sumstat_file} ${base}\n        mv ${gnomad_ref} ${gnomad_ref_base}\n\n        echo \"`date` harmonizing stats with gnomAD\"\n        python3 /META_ANALYSIS/scripts/harmonize.py ${base} ${gnomad_ref_base} ${n} ${options}\\\n        | bgzip > ${base}.${gnomad_ref_base} && \\\n        tabix -S 1 -s 1 -b 2 -e 2 ${base}.${gnomad_ref_base} && \\\n        echo \"`date` done\"\n\n    >>>\n\n    output {\n        File out = base + \".\" + gnomad_ref_base\n        File out_tbi = base + \".\" + gnomad_ref_base + \".tbi\"\n    }\n\n    runtime {\n        docker: \"${docker}\"\n        cpu: \"1\"\n        memory: \"2 GB\"\n        disks: \"local-disk 200 HDD\"\n        zones: \"us-east1-d\"\n        preemptible: 2\n        noAddress: true\n    }\n}\n\ntask flip_mahalanobis {\n\n    String docker\n    File sumstat_file\n    Int sd\n    String outfile = basename(sumstat_file, \".gz\") + \".mahalanobis_filt_\" + sd + \"sd\"\n\n    command <<<\n\n        python3 - <<EOF\n\n        from scipy.spatial.distance import mahalanobis\n        import scipy as sp\n        import pandas as pd\n        import numpy as np\n        import re\n\n        data = pd.read_csv('${sumstat_file}', sep='\\t')\n        gnomad_col = list(filter(re.compile('AF_gnomad_v3_b38_ref_').match, data.columns))[0]\n\n        # flip frequencies and betas\n        data['flipped'] = np.where(((data['AF_Allele2'] > 0.6) & (data[gnomad_col] < 0.4)) | ((data['AF_Allele2'] < 0.4) & (data[gnomad_col] > 0.6)), 1, 0)\n        data['AF_Allele2'] = np.where(data['flipped'] == 1, 1-data['AF_Allele2'], data['AF_Allele2'])\n        data['AF_fc'] = np.where(data['flipped'] == 1, data['AF_Allele2']/data[gnomad_col], data['AF_fc'])\n        data['BETA'] = np.where(data['flipped'] == 1, -data['BETA'], data['BETA'])\n\n        # calculate squared mahalanobis distance based on non-X variants\n        try:\n            afs = data[data['#CHR'] != 23][['AF_Allele2', gnomad_col]]\n            inv_cov = sp.linalg.inv(afs.cov().values)\n            mean = afs.mean().values\n            data['mahalanobis2'] = afs.apply(lambda row: mahalanobis(row, mean, inv_cov) ** 2, axis=1)\n            # filter data based on mahalanobis except X chr\n            mean = np.mean(data['mahalanobis2'])\n            sd = np.std(data['mahalanobis2'])\n            data = data[(data['#CHR'] == 23) | ((data['mahalanobis2'] > mean - ${sd} * sd) & (data['mahalanobis2'] < mean + ${sd} * sd))]\n        except np.linalg.LinAlgError: # singular matrix if AF is fixed\n            data['mahalanobis2'] = np.nan\n\n        data.to_csv('${outfile}', index=False, na_rep=\"NA\", sep='\\t')\n        EOF\n\n        bgzip -@4 ${outfile}\n        tabix -S 1 -s 1 -b 2 -e 2 ${outfile}.gz\n\n    >>>\n\n    output {\n        File out = outfile + \".gz\"\n        File out_tbi = outfile + \".gz.tbi\"\n    }\n\n    runtime {\n        docker: \"${docker}\"\n        cpu: \"1\"\n        # TODO memory by file size\n        memory: \"20 GB\"\n        disks: \"local-disk 200 HDD\"\n        zones: \"us-east1-d\"\n        preemptible: 2\n        noAddress: true\n    }\n}\n\ntask plot {\n\n    File sumstat_file\n    String base = basename(sumstat_file)\n    String prefix = sub(base, \"\\\\.txt.*\", \"\")\n    Int loglog_ylim\n    String pop\n    String docker\n\n    command <<<\n\n        gunzip -c ${sumstat_file} | awk '\n        BEGIN {FS=OFS=\"\\t\"}\n        NR==1 {for(i=1;i<=NF;i++) { a[$i]=i; if ($i==\"#CHR\" || $i==\"POS\" || $i==\"p.value\" || $i~\"AF_\") b[i]=1}}\n        {sep=\"\"; for(i=1;i<=NF;i++) if (b[i]==1) { printf sep\"\"$i; sep=\"\\t\"} printf \"\\n\"}\n        ' | bgzip > ${base} && \\\n\n        Rscript - <<EOF\n        require(ggplot2)\n        require(data.table)\n        options(bitmapType='cairo')\n        data <- fread(\"${base}\")\n        png(\"${base}_AF.png\", width=1000, height=1000, units=\"px\")\n        p <- ggplot(data, aes_string(x=\"AF_Allele2\", y=\"AF_gnomad_v3_b38_ref_${pop}\")) +\n          geom_point(alpha=0.1) +\n          xlab(\"AF_${base}\") +\n          theme_minimal(base_size=18)\n        print(p)\n        dev.off()\n        EOF\n\n        qqplot.R --file ${base} --bp_col \"POS\" --chrcol \"#CHR\" --pval_col \"p.value\" --loglog_ylim ${loglog_ylim}\n        [[ ! \"${base}\" =~ \"HOSTAGE\" && ! \"${base}\" =~ \"Ancestry\" ]] && qq_plot.R --input=${base} --prefix=${prefix} --af=AF_Allele2 --pvalue=p.value || echo \"qq_plot.R not run\"\n    >>>\n\n    output {\n        Array[File] pngs = glob(\"*.png\")\n    }\n\n    runtime {\n        docker: \"${docker}\"\n        cpu: \"1\"\n        memory: 10*ceil(size(sumstat_file, \"G\")) + \" GB\"\n        disks: \"local-disk 200 HDD\"\n        zones: \"us-east1-d\"\n        preemptible: 2\n        noAddress: true\n    }\n}\n\nworkflow munge_sumstats {\n\n    File sumstats_loc\n    Array[Array[String]] sumstat_files = read_tsv(sumstats_loc)\n    String gnomad_ref_template\n\n    scatter (sumstat_file in sumstat_files) {\n        call clean_filter {\n            input: sumstat_file=sumstat_file[0]\n        }\n        call lift {\n            input: sumstat_file=clean_filter.out\n        }\n        call harmonize {\n            input: sumstat_file=lift.out, gnomad_ref=sub(gnomad_ref_template, \"POP\", sumstat_file[1]), n=sumstat_file[2]\n        }\n        #call flip_mahalanobis {\n        #    input: sumstat_file=harmonize.out\n        #}\n        #call plot {\n        #    input: sumstat_file=flip_mahalanobis.out, pop=sumstat_file[1]\n        #}\n        call plot {\n            input: sumstat_file=harmonize.out, pop=sumstat_file[1]\n        }\n    }\n}\n","root":"","options":"{\n\n}","inputs":"{\"munge_sumstats.clean_filter.af_col\":\"AF_Allele2\",\"munge_sumstats.clean_filter.docker\":\"gcr.io/covid-19-hg/saige:0.36.3.2-2\",\"munge_sumstats.clean_filter.info_col\":\"imputationInfo\",\"munge_sumstats.clean_filter.min_af\":0.001,\"munge_sumstats.clean_filter.min_info\":0.6,\"munge_sumstats.flip_mahalanobis.docker\":\"gcr.io/covid-19-hg/meta:1d50c\",\"munge_sumstats.flip_mahalanobis.sd\":3,\"munge_sumstats.gnomad_ref_template\":\"gs://covid19-hg-analysis/gnomad/v3/filter/gnomad_v3_b38_ref_POP.gz\",\"munge_sumstats.harmonize.docker\":\"gcr.io/covid-19-hg/meta:1d50c\",\"munge_sumstats.harmonize.options\":\"\",\"munge_sumstats.lift.b37_ref\":\"gs://covid19-hg-analysis/recomb_map/37/plink.chr21.GRCh37.map.txt\",\"munge_sumstats.lift.b38_ref\":\"gs://covid19-hg-analysis/recomb_map/38/plink.chr21.GRCh38.map.txt\",\"munge_sumstats.lift.docker\":\"gcr.io/covid-19-hg/meta:1d50c\",\"munge_sumstats.plot.docker\":\"gcr.io/covid-19-hg/plots:0.2\",\"munge_sumstats.plot.loglog_ylim\":30,\"munge_sumstats.sumstats_loc\":\"gs://covid19-hg-analysis/20211123/conf/munge_20211123.txt\"}","workflowUrl":"","labels":"{}"},"calls":{"munge_sumstats.sumstat_files":[{"retryableFailure":false,"executionStatus":"Failed","shardIndex":-1,"failures":[{"message":"Failed to evaluate 'munge_sumstats.sumstat_files' (reason 1 of 1): Evaluating read_tsv(sumstats_loc) failed: java.lang.IllegalArgumentException: Could not build the path \"gs://covid19-hg-analysis/20211123/conf/munge_20211123.txt\". It may refer to a filesystem not supported by this instance of Cromwell. Supported filesystems are: HTTP, LinuxFileSystem. Failures: \nHTTP: gs://covid19-hg-analysis/20211123/conf/munge_20211123.txt does not have an http or https scheme (IllegalArgumentException)\nLinuxFileSystem: Cannot build a local path from gs://covid19-hg-analysis/20211123/conf/munge_20211123.txt (RuntimeException)\n Please refer to the documentation for more information on how to configure filesystems: http://cromwell.readthedocs.io/en/develop/backends/HPC/#filesystems","causedBy":[]}],"end":"2021-11-24T16:14:51.784Z","attempt":1}]},"outputs":{},"workflowRoot":"/cromwell-working-dir/cromwell-executions/munge_sumstats/b8ac7d59-d30e-498b-b644-de34ce223045","actualWorkflowLanguage":"WDL","id":"b8ac7d59-d30e-498b-b644-de34ce223045","inputs":{"munge_sumstats.lift.dollar":"$","munge_sumstats.clean_filter.docker":"gcr.io/covid-19-hg/saige:0.36.3.2-2","munge_sumstats.harmonize.options":"","munge_sumstats.sumstats_loc":"gs://covid19-hg-analysis/20211123/conf/munge_20211123.txt","munge_sumstats.clean_filter.min_af":0.001,"munge_sumstats.lift.b37_ref":"gs://covid19-hg-analysis/recomb_map/37/plink.chr21.GRCh37.map.txt","munge_sumstats.harmonize.docker":"gcr.io/covid-19-hg/meta:1d50c","munge_sumstats.lift.b38_ref":"gs://covid19-hg-analysis/recomb_map/38/plink.chr21.GRCh38.map.txt","munge_sumstats.clean_filter.info_col":"imputationInfo","munge_sumstats.clean_filter.dollar":"$","munge_sumstats.clean_filter.min_info":0.6,"munge_sumstats.plot.docker":"gcr.io/covid-19-hg/plots:0.2","munge_sumstats.clean_filter.af_col":"AF_Allele2","munge_sumstats.plot.loglog_ylim":30,"munge_sumstats.lift.docker":"gcr.io/covid-19-hg/meta:1d50c","munge_sumstats.gnomad_ref_template":"gs://covid19-hg-analysis/gnomad/v3/filter/gnomad_v3_b38_ref_POP.gz"},"labels":{"cromwell-workflow-id":"cromwell-b8ac7d59-d30e-498b-b644-de34ce223045"},"submission":"2021-11-24T16:14:45.196Z","status":"Failed","failures":[{"causedBy":[{"message":"Failed to evaluate 'munge_sumstats.sumstat_files' (reason 1 of 1): Evaluating read_tsv(sumstats_loc) failed: java.lang.IllegalArgumentException: Could not build the path \"gs://covid19-hg-analysis/20211123/conf/munge_20211123.txt\". It may refer to a filesystem not supported by this instance of Cromwell. Supported filesystems are: HTTP, LinuxFileSystem. Failures: \nHTTP: gs://covid19-hg-analysis/20211123/conf/munge_20211123.txt does not have an http or https scheme (IllegalArgumentException)\nLinuxFileSystem: Cannot build a local path from gs://covid19-hg-analysis/20211123/conf/munge_20211123.txt (RuntimeException)\n Please refer to the documentation for more information on how to configure filesystems: http://cromwell.readthedocs.io/en/develop/backends/HPC/#filesystems","causedBy":[]}],"message":"Workflow failed"}],"end":"2021-11-24T16:14:52.851Z","start":"2021-11-24T16:14:47.600Z"}