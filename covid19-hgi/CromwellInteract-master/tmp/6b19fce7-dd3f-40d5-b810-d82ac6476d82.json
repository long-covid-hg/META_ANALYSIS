{"workflowName":"meta_analysis","workflowProcessingEvents":[{"cromwellId":"cromid-c0c1e5a","description":"PickedUp","timestamp":"2022-04-01T13:04:19.480Z","cromwellVersion":"53-fc98e98"},{"cromwellId":"cromid-c0c1e5a","description":"Finished","timestamp":"2022-04-01T13:05:38.351Z","cromwellVersion":"53-fc98e98"}],"metadataSource":"Unarchived","actualWorkflowLanguageVersion":"1.0","submittedFiles":{"workflow":"version 1.0\n\nworkflow meta_analysis {\n\n    input {\n        File sumstats_loc\n        File pheno_confs\n\n        Array[Array[String]] sumstat_files = read_tsv(sumstats_loc)\n        Array[String] pheno_conf = read_lines(pheno_confs)\n    }\n\n    scatter (i in range(length(pheno_conf))) {\n\n        String pheno = basename(pheno_conf[i], \".json\")\n        \n        scatter (chr in range(23)) {\n            call run_range {\n                input:\n                    pheno = pheno,\n                    conf = pheno_conf[i],\n                    sumstat_files = sumstat_files[i],\n                    chrom = chr+1\n            }\n        }\n\n        call combine_chrom_metas {\n            input:\n                pheno = pheno,\n                meta_outs = run_range.out\n        }\n\n        call add_rsids {\n            input:\n                meta_file = combine_chrom_metas.meta_out\n        }\n\n        call meta_qq {\n            input:\n                meta_file = combine_chrom_metas.meta_out\n        }\n\n        call post_filter {\n            input:\n                meta_file = add_rsids.meta_out\n        }\n\n    }\n\n    output {\n        Array[File] metas = combine_chrom_metas.meta_out\n        Array[File] metas_with_rsids = add_rsids.meta_out\n        Array[File] filtered_metas = post_filter.filtered_meta_out\n        Array[Array[File]] meta_pngs = meta_qq.pngs\n        Array[Array[File]] meta_lambdas = meta_qq.lambdas\n    }\n}\n\n# Run meta-analysis for each chromosome separately\ntask run_range {\n\n    input {\n        Array[File] sumstat_files\n        String pheno\n        String chrom\n        File conf\n\n        String docker\n        String method\n        String opts\n    }\n\n    command <<<\n\n        echo \"`date` GWAS meta-analysis\"\n        echo \"docker: ~{docker}\"\n        echo \"pheno: ~{pheno}\"\n        echo \"method: ~{method}\"\n        echo \"options: ~{opts}\"\n        echo \"chromosome: ~{chrom}\"\n        echo \"conf: ~{conf}\"\n\n        /META_ANALYSIS/scripts/meta_analysis.py ~{conf} ~{pheno}_chr~{chrom}_meta_out.tsv ~{method} ~{opts} --chrom ~{chrom}\n\n        echo \"`date` done\"\n    >>>\n\n    output {\n        File out = pheno + \"_chr\" + chrom + \"_meta_out.tsv.gz\"\n    }\n\n    runtime {\n        docker: \"~{docker}\"\n        cpu: 1\n        memory: \"10 GB\"\n        disks: \"local-disk \" + 4 * ceil(size(sumstat_files, \"GB\") + 1) + \" HDD\"\n        zones: \"us-central1-b\"\n        preemptible: 2\n        noAddress: true\n    }\n}\n\n# Combine separately run meta-analysis result files\ntask combine_chrom_metas {\n\n    input {\n        Array[File] meta_outs\n        String pheno\n\n        String docker\n    }\n\n    command <<<\n\n        echo \"`date` Combining metadata files\"\n        echo \"docker: ~{docker}\"\n        echo \"pheno: ~{pheno}\"\n\n        cat <(zcat ~{meta_outs[0]} | head -1) \\\n            <(for file in ~{sep=\" \" meta_outs}; do\n                zcat $file | tail -n +2;\n            done) \\\n        | bgzip > ~{pheno}_meta_out.tsv.gz\n\n        echo \"`date` tabixing\"\n        tabix -s 1 -b 2 -e 2 ~{pheno}_meta_out.tsv.gz\n        echo \"`date` done\"\n    >>>\n\n    output {\n        File meta_out = pheno + \"_meta_out.tsv.gz\"\n        File meta_out_tbi = pheno + \"_meta_out.tsv.gz.tbi\"\n    }\n    \n    runtime {\n        docker: \"~{docker}\"\n        cpu: 1\n        memory: \"10 GB\"\n        disks: \"local-disk \" + 4 * ceil(size(meta_outs, \"GB\") + 1) + \" HDD\"\n        zones: \"us-central1-b\"\n        preemptible: 2\n        noAddress: true\n    }\n}\n\n# Add rsids\ntask add_rsids {\n\n    input {\n        File meta_file\n\n        File ref_file\n        String docker\n\n        String base = basename(meta_file, \".tsv.gz\")\n    }\n\n    command <<<\n\n        set -euxo pipefail\n\n        echo \"`date` Adding rsids\"\n\n        python3 <<EOF | bgzip > ~{base}.tsv.gz\n\n        import gzip\n\n        fp_ref = gzip.open('~{ref_file}', 'rt')\n        ref_has_lines = True\n        ref_chr = 1\n        ref_pos = 0\n        ref_line = fp_ref.readline()\n        while ref_line.startswith(\"##\"):\n            ref_line = fp_ref.readline()\n        if ref_line.startswith('#'):\n            assert ref_line.rstrip('\\r\\n').split('\\t') == '#CHROM POS ID REF ALT QUAL FILTER INFO'.split(), repr(ref_line)\n        ref_h_idx = {h:i for i,h in enumerate(ref_line.rstrip('\\r\\n').split('\\t'))}\n\n        with gzip.open('~{meta_file}', 'rt') as f:\n            header = f.readline().strip()\n            h_idx = {h:i for i,h in enumerate(header.split('\\t'))}\n            print(header + '\\trsid')\n            for line in f:\n                line = line.strip()\n                s = line.split('\\t')\n                chr = int(s[h_idx['#CHR']])\n                pos = int(s[h_idx['POS']])\n                ref = s[h_idx['REF']]\n                alt = s[h_idx['ALT']]\n                ref_vars = []\n                while ref_has_lines and int(ref_chr) < chr or (int(ref_chr) == chr and ref_pos < pos):\n                    ref_line = fp_ref.readline().rstrip('\\r\\n').split('\\t')\n                    try:\n                        ref_chr = ref_line[ref_h_idx['#CHROM']]\n                        ref_pos = int(ref_line[ref_h_idx['POS']])\n                    except ValueError:\n                        ref_has_lines = False\n                while ref_has_lines and int(ref_chr) == chr and ref_pos == pos:\n                    ref_vars.append(ref_line)\n                    ref_line = fp_ref.readline().strip().split('\\t')\n                    try:\n                        ref_chr = ref_line[ref_h_idx['#CHROM']]\n                        ref_pos = int(ref_line[ref_h_idx['POS']])\n                    except ValueError:\n                        ref_has_lines = False\n\n                rsid = 'NA'\n                for r in ref_vars:\n                    if r[ref_h_idx['REF']] == ref and alt in r[ref_h_idx['ALT']].split(','):\n                        rsid = r[ref_h_idx['ID']]\n                        break\n\n                print(line + '\\t' + rsid)\n\n        EOF\n\n        echo \"`date` tabixing\"\n        tabix -s 1 -b 2 -e 2 ~{base}.tsv.gz\n        echo \"`date` done\"\n\n    >>>\n\n    output {\n        File meta_out = base + \".tsv.gz\"\n        File out_tbi = base + \".tsv.gz.tbi\"\n    }\n\n    runtime {\n        docker: \"~{docker}\"\n        cpu: \"1\"\n        memory: \"10 GB\"\n        disks: \"local-disk \" + 4*ceil(size(meta_file, \"G\") + size(ref_file, \"G\")) + \" SSD\"\n        zones: \"us-central1-b\"\n        preemptible: 2\n        noAddress: true\n    }\n\n}\n\n# Generate qq and manhattan plots from meta-analysis results\ntask meta_qq {\n\n    input {\n        File meta_file\n\n        Int loglog_ylim\n        String docker\n        String pvals_to_plot\n\n        String base = basename(meta_file)\n    }\n\n    command <<<\n\n        set -euxo pipefail\n\n        mv ~{meta_file} ~{base}\n\n        /META_ANALYSIS/scripts/qqplot.R --file ~{base} --bp_col \"POS\" --chrcol \"#CHR\" --pval_col ~{pvals_to_plot} --loglog_ylim ~{loglog_ylim}\n\n    >>>\n\n    output {\n        Array[File] pngs = glob(\"*.png\")\n        Array[File] lambdas = glob(\"*.txt\")\n    }\n\n    runtime {\n        docker: \"~{docker}\"\n        cpu: \"1\"\n        memory: \"30 GB\"\n        disks: \"local-disk \" + 20*ceil(size(meta_file, \"G\")) + \" HDD\"\n        zones: \"us-central1-b\"\n        preemptible: 2\n        noAddress: true\n    }\n}\n\n# Filter out variants not in the left-most study (usually Finngen)\ntask post_filter {\n\n    input {\n        File meta_file\n\n        String docker\n\n        String base = basename(meta_file, \".tsv.gz\")\n    }\n\n    command <<<\n\n        set -exo pipefail\n\n        # Use the first '_beta' suffix column as the beta of the left-most variant. If NA --> remove variant\n        zcat ~{meta_file} | awk -v OFS='\\t' '\n        NR==1 {for(i=1;i<=NF;i++) if($i~\"_beta$\") {beta_col=i; break} print $0}\n        (NR>1 && $beta_col != \"NA\") {print}\n        ' | bgzip > ~{base}_filtered.tsv.gz\n        tabix -s 1 -b 2 -e 2 ~{base}_filtered.tsv.gz\n\n    >>>\n\n    output {\n        File filtered_meta_out = base + \"_filtered.tsv.gz\"\n        File filtered_meta_out_tbi = base + \"_filtered.tsv.gz.tbi\"\n    }\n\n    runtime {\n        docker: \"~{docker}\"\n        cpu: \"1\"\n        memory: \"2 GB\"\n        disks: \"local-disk \" + 3*ceil(size(meta_file, \"G\")) + \" HDD\"\n        zones: \"us-central1-b\"\n        preemptible: 2\n        noAddress: true\n    }\n}\n","root":"","options":"{\n\n}","inputs":"{\"meta_analysis.add_rsids.docker\":\"gcr.io/long-covid-hg/bioinformatics:0.7\",\"meta_analysis.add_rsids.ref_file\":\"gs://long-covid-hg-cromwell/dbsnp/dbsnp_hg38p13_b153_numerical.vcf.gz\",\"meta_analysis.combine_chrom_metas.docker\":\"gcr.io/long-covid-hg/bioinformatics:0.7\",\"meta_analysis.meta_qq.docker\":\"gcr.io/long-covid-hg/meta:7.42\",\"meta_analysis.meta_qq.loglog_ylim\":20,\"meta_analysis.meta_qq.pvals_to_plot\":\"all_inv_var_meta_p,all_inv_var_het_p\",\"meta_analysis.pheno_confs\":\"gs://long-covid-hg-cromwell/20220331/conf/step3_pheno_conf.txt\",\"meta_analysis.post_filter.docker\":\"gcr.io/long-covid-hg/bioinformatics:0.7\",\"meta_analysis.run_range.docker\":\"gcr.io/long-covid-hg/meta:7.42\",\"meta_analysis.run_range.method\":\"inv_var\",\"meta_analysis.run_range.opts\":\"--is_het_test --dont_allow_space --leave_one_out\",\"meta_analysis.sumstats_loc\":\"gs://long-covid-hg-cromwell/20220331/conf/step3_sumstats_loc.txt\"}","workflowUrl":"","labels":"{}"},"calls":{"__pheno_conf":[{"retryableFailure":false,"executionStatus":"Failed","shardIndex":-1,"failures":[{"causedBy":[],"message":"Failed to evaluate '__pheno_conf' (reason 1 of 1): Evaluating select_first([pheno_conf, read_lines(pheno_confs)]) failed: Failed to read_lines(\"gs://long-covid-hg-cromwell/20220331/conf/step3_pheno_conf.txt\") (reason 1 of 1): Futures timed out after [60 seconds]"}],"end":"2022-04-01T13:05:37.336Z","attempt":1}]},"outputs":{},"workflowRoot":"gs://long-covid-hg-cromwell/meta_analysis/6b19fce7-dd3f-40d5-b810-d82ac6476d82/","actualWorkflowLanguage":"WDL","id":"6b19fce7-dd3f-40d5-b810-d82ac6476d82","inputs":{"pheno_confs":"gs://long-covid-hg-cromwell/20220331/conf/step3_pheno_conf.txt","meta_analysis.add_rsids.ref_file":"gs://long-covid-hg-cromwell/dbsnp/dbsnp_hg38p13_b153_numerical.vcf.gz","meta_analysis.meta_qq.pvals_to_plot":"all_inv_var_meta_p,all_inv_var_het_p","meta_analysis.run_range.opts":"--is_het_test --dont_allow_space --leave_one_out","pheno_conf":null,"meta_analysis.add_rsids.base":null,"meta_analysis.run_range.method":"inv_var","sumstat_files":null,"meta_analysis.meta_qq.loglog_ylim":20,"sumstats_loc":"gs://long-covid-hg-cromwell/20220331/conf/step3_sumstats_loc.txt","meta_analysis.add_rsids.docker":"gcr.io/long-covid-hg/bioinformatics:0.7","meta_analysis.meta_qq.base":null,"meta_analysis.run_range.docker":"gcr.io/long-covid-hg/meta:7.42","meta_analysis.meta_qq.docker":"gcr.io/long-covid-hg/meta:7.42","meta_analysis.post_filter.docker":"gcr.io/long-covid-hg/bioinformatics:0.7","meta_analysis.combine_chrom_metas.docker":"gcr.io/long-covid-hg/bioinformatics:0.7","meta_analysis.post_filter.base":null},"labels":{"cromwell-workflow-id":"cromwell-6b19fce7-dd3f-40d5-b810-d82ac6476d82"},"submission":"2022-04-01T13:04:18.628Z","status":"Failed","failures":[{"causedBy":[{"causedBy":[],"message":"Failed to evaluate '__pheno_conf' (reason 1 of 1): Evaluating select_first([pheno_conf, read_lines(pheno_confs)]) failed: Failed to read_lines(\"gs://long-covid-hg-cromwell/20220331/conf/step3_pheno_conf.txt\") (reason 1 of 1): Futures timed out after [60 seconds]"}],"message":"Workflow failed"}],"end":"2022-04-01T13:05:38.351Z","start":"2022-04-01T13:04:19.481Z"}